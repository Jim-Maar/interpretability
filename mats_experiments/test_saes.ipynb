{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sae-lens in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (3.17.1)\n",
      "Requirement already satisfied: transformer-lens in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (2.0.0)\n",
      "Requirement already satisfied: circuitsvis in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (0.0.0)\n",
      "Requirement already satisfied: automated-interpretability<1.0.0,>=0.0.5 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from sae-lens) (0.0.5)\n",
      "Requirement already satisfied: babe<0.0.8,>=0.0.7 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from sae-lens) (0.0.7)\n",
      "Requirement already satisfied: datasets<3.0.0,>=2.17.1 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from sae-lens) (2.19.1)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.8.3 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from sae-lens) (3.9.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.6 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from sae-lens) (0.1.7)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from sae-lens) (3.9.1)\n",
      "Requirement already satisfied: plotly<6.0.0,>=5.19.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from sae-lens) (5.22.0)\n",
      "Requirement already satisfied: plotly-express<0.5.0,>=0.4.1 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from sae-lens) (0.4.1)\n",
      "Requirement already satisfied: pytest-profiling<2.0.0,>=1.7.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from sae-lens) (1.7.0)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from sae-lens) (1.0.1)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from sae-lens) (6.0.1)\n",
      "Requirement already satisfied: pyzmq==26.0.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from sae-lens) (26.0.0)\n",
      "Requirement already satisfied: safetensors<0.5.0,>=0.4.2 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from sae-lens) (0.4.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.38.1 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from sae-lens) (4.41.2)\n",
      "Requirement already satisfied: typer<0.13.0,>=0.12.3 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from sae-lens) (0.12.4)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.10.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from sae-lens) (4.12.0)\n",
      "Requirement already satisfied: zstandard<0.23.0,>=0.22.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from sae-lens) (0.22.0)\n",
      "Requirement already satisfied: accelerate>=0.23.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from transformer-lens) (0.30.1)\n",
      "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from transformer-lens) (0.14.1)\n",
      "Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from transformer-lens) (0.0.3)\n",
      "Requirement already satisfied: einops>=0.6.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from transformer-lens) (0.7.0)\n",
      "Requirement already satisfied: fancy-einsum>=0.0.3 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from transformer-lens) (0.0.3)\n",
      "Requirement already satisfied: jaxtyping>=0.2.11 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from transformer-lens) (0.2.29)\n",
      "Requirement already satisfied: numpy>=1.24 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from transformer-lens) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from transformer-lens) (2.2.2)\n",
      "Requirement already satisfied: rich>=12.6.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from transformer-lens) (13.7.1)\n",
      "Requirement already satisfied: sentencepiece in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from transformer-lens) (0.2.0)\n",
      "Requirement already satisfied: torch>=1.10 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from transformer-lens) (2.3.0.post100)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from transformer-lens) (4.66.4)\n",
      "Requirement already satisfied: wandb>=0.13.5 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from transformer-lens) (0.13.10)\n",
      "Requirement already satisfied: importlib-metadata<6.0.0,>=5.1.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from circuitsvis) (5.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from accelerate>=0.23.0->transformer-lens) (24.0)\n",
      "Requirement already satisfied: psutil in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from accelerate>=0.23.0->transformer-lens) (5.9.8)\n",
      "Requirement already satisfied: huggingface-hub in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from accelerate>=0.23.0->transformer-lens) (0.23.2)\n",
      "Requirement already satisfied: blobfile<3.0.0,>=2.1.1 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (2.1.1)\n",
      "Requirement already satisfied: boostedblob<0.16.0,>=0.15.3 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (0.15.4)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.10.1 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (3.10.7)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (1.5.0)\n",
      "Requirement already satisfied: tiktoken<0.7.0,>=0.6.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (0.6.0)\n",
      "Requirement already satisfied: py2store in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from babe<0.0.8,>=0.0.7->sae-lens) (0.1.20)\n",
      "Requirement already satisfied: graze in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from babe<0.0.8,>=0.0.7->sae-lens) (0.1.24)\n",
      "Requirement already satisfied: filelock in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (3.14.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (2.28.1)\n",
      "Requirement already satisfied: xxhash in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets<3.0.0,>=2.17.1->sae-lens) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (3.9.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from importlib-metadata<6.0.0,>=5.1.0->circuitsvis) (3.19.0)\n",
      "Requirement already satisfied: typeguard==2.13.3 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from jaxtyping>=0.2.11->transformer-lens) (2.13.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (4.52.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (2.9.0.post0)\n",
      "Requirement already satisfied: traitlets in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from matplotlib-inline<0.2.0,>=0.1.6->sae-lens) (5.14.3)\n",
      "Requirement already satisfied: click in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->sae-lens) (8.1.7)\n",
      "Requirement already satisfied: joblib in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->sae-lens) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->sae-lens) (2024.5.15)\n",
      "Requirement already satisfied: pytz>=2020.1 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from pandas>=1.1.5->transformer-lens) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from pandas>=1.1.5->transformer-lens) (2024.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from plotly<6.0.0,>=5.19.0->sae-lens) (8.3.0)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from plotly-express<0.5.0,>=0.4.1->sae-lens) (0.14.2)\n",
      "Requirement already satisfied: scipy>=0.18 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from plotly-express<0.5.0,>=0.4.1->sae-lens) (1.13.1)\n",
      "Requirement already satisfied: patsy>=0.5 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from plotly-express<0.5.0,>=0.4.1->sae-lens) (0.5.6)\n",
      "Requirement already satisfied: six in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from pytest-profiling<2.0.0,>=1.7.0->sae-lens) (1.16.0)\n",
      "Requirement already satisfied: pytest in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from pytest-profiling<2.0.0,>=1.7.0->sae-lens) (8.2.1)\n",
      "Requirement already satisfied: gprof2dot in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from pytest-profiling<2.0.0,>=1.7.0->sae-lens) (2024.6.6)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from rich>=12.6.0->transformer-lens) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from rich>=12.6.0->transformer-lens) (2.18.0)\n",
      "Requirement already satisfied: sympy in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from torch>=1.10->transformer-lens) (1.12)\n",
      "Requirement already satisfied: networkx in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from torch>=1.10->transformer-lens) (3.3)\n",
      "Requirement already satisfied: jinja2 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from torch>=1.10->transformer-lens) (3.1.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from transformers<5.0.0,>=4.38.1->sae-lens) (0.19.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from typer<0.13.0,>=0.12.3->sae-lens) (1.5.4)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens) (3.1.43)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens) (2.3.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens) (0.4.0)\n",
      "Requirement already satisfied: pathtools in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens) (69.5.1)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from wandb>=0.13.5->transformer-lens) (3.20.3)\n",
      "Requirement already satisfied: pycryptodomex~=3.8 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from blobfile<3.0.0,>=2.1.1->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (3.20.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from blobfile<3.0.0,>=2.1.1->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (1.26.19)\n",
      "Requirement already satisfied: lxml~=4.9 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from blobfile<3.0.0,>=2.1.1->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (4.9.4)\n",
      "Requirement already satisfied: uvloop>=0.16.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from boostedblob<0.16.0,>=0.15.3->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (0.20.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens) (1.9.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from GitPython>=1.0.0->wandb>=0.13.5->transformer-lens) (4.0.11)\n",
      "Requirement already satisfied: anyio in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (4.4.0)\n",
      "Requirement already satisfied: certifi in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (1.0.5)\n",
      "Requirement already satisfied: idna in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (3.7)\n",
      "Requirement already satisfied: sniffio in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (0.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from requests>=2.19.0->datasets<3.0.0,>=2.17.1->sae-lens) (2.0.4)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from scikit-learn<2.0.0,>=1.2.0->automated-interpretability<1.0.0,>=0.0.5->sae-lens) (3.5.0)\n",
      "Requirement already satisfied: dol in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from graze->babe<0.0.8,>=0.0.7->sae-lens) (0.2.62)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from jinja2->torch>=1.10->transformer-lens) (2.1.3)\n",
      "Requirement already satisfied: config2py in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from py2store->babe<0.0.8,>=0.0.7->sae-lens) (0.1.36)\n",
      "Requirement already satisfied: importlib-resources in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from py2store->babe<0.0.8,>=0.0.7->sae-lens) (6.4.0)\n",
      "Requirement already satisfied: iniconfig in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from pytest->pytest-profiling<2.0.0,>=1.7.0->sae-lens) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=1.5 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from pytest->pytest-profiling<2.0.0,>=1.7.0->sae-lens) (1.5.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from sympy->torch>=1.10->transformer-lens) (1.2.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb>=0.13.5->transformer-lens) (5.0.1)\n",
      "Requirement already satisfied: i2 in /hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages (from config2py->py2store->babe<0.0.8,>=0.0.7->sae-lens) (0.1.27)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #import google.colab # type: ignore\n",
    "    #from google.colab import output\n",
    "    %pip install sae-lens transformer-lens circuitsvis\n",
    "except:\n",
    "    from IPython import get_ipython # type: ignore\n",
    "    ipython = get_ipython(); assert ipython is not None\n",
    "    ipython.run_line_magic(\"load_ext\", \"autoreload\")\n",
    "    ipython.run_line_magic(\"autoreload\", \"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-1L-21M into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"tiny-stories-1L-21M\"\n",
    ")  # This will wrap huggingface models and has lots of nice utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "from sae_lens import LanguageModelSAERunnerConfig, SAETrainingRunner\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: 16384-L1-5-LR-5e-05-Tokens-1.600e+02\n",
      "n_tokens_per_buffer (millions): 0.524288\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.001024\n",
      "Total training steps: 10\n",
      "Total wandb updates: 0\n",
      "n_tokens_per_feature_sampling_window (millions): 8.192\n",
      "n_tokens_per_dead_feature_window (millions): 8.192\n",
      "We will reset the sparsity calculation 0 times.\n",
      "Number tokens in sparsity calculation window: 1.60e+04\n",
      "Loaded pretrained model tiny-stories-1L-21M into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjim-maar\u001b[0m (\u001b[33mfeedback2code\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/hpi/fs00/home/jim.maar/interpretability/mats_experiments/wandb/run-20240822_133914-zakhrgly</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/feedback2code/sae_lens_tutorial/runs/zakhrgly' target=\"_blank\">16384-L1-5-LR-5e-05-Tokens-1.600e+02</a></strong> to <a href='https://wandb.ai/feedback2code/sae_lens_tutorial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/feedback2code/sae_lens_tutorial' target=\"_blank\">https://wandb.ai/feedback2code/sae_lens_tutorial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/feedback2code/sae_lens_tutorial/runs/zakhrgly' target=\"_blank\">https://wandb.ai/feedback2code/sae_lens_tutorial/runs/zakhrgly</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating norm scaling factor: 100%|██████████| 1000/1000 [01:02<00:00, 15.92it/s]\n",
      "Training SAE:   0%|          | 0/160 [01:04<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">16384-L1-5-LR-5e-05-Tokens-1.600e+02</strong> at: <a href='https://wandb.ai/feedback2code/sae_lens_tutorial/runs/zakhrgly' target=\"_blank\">https://wandb.ai/feedback2code/sae_lens_tutorial/runs/zakhrgly</a><br/>Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240822_133914-zakhrgly/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_training_steps = 10  # probably we should do more\n",
    "batch_size = 16  # we could go higher but we want to see the stats.\n",
    "total_training_tokens = total_training_steps * batch_size\n",
    "\n",
    "lr_warm_up_steps = 0\n",
    "lr_decay_steps = total_training_steps // 5  # 20% of training\n",
    "l1_warm_up_steps = total_training_steps // 20  # 5% of training\n",
    "\n",
    "cfg = LanguageModelSAERunnerConfig(\n",
    "    # Data Generating Function (Model + Training Distibuion)\n",
    "    model_name=\"tiny-stories-1L-21M\",  # our model (more options here: https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html)\n",
    "    hook_name=\"blocks.0.hook_mlp_out\",  # A valid hook point (see more details here: https://neelnanda-io.github.io/TransformerLens/generated/demos/Main_Demo.html#Hook-Points)\n",
    "    hook_layer=0,  # Only one layer in the model.\n",
    "    d_in=1024,  # the width of the mlp output.\n",
    "    dataset_path=\"apollo-research/roneneldan-TinyStories-tokenizer-gpt2\",  # this is a tokenized language dataset on Huggingface for the Tiny Stories corpus.\n",
    "    is_dataset_tokenized=True,\n",
    "    streaming=True,  # we could pre-download the token dataset if it was small.\n",
    "    # SAE Parameters\n",
    "    mse_loss_normalization=None,  # We won't normalize the mse loss,\n",
    "    expansion_factor=16,  # the width of the SAE. Larger will result in better stats but slower training.\n",
    "    b_dec_init_method=\"zeros\",  # The geometric median can be used to initialize the decoder weights.\n",
    "    apply_b_dec_to_input=False,  # We won't apply the decoder weights to the input.\n",
    "    normalize_sae_decoder=False,\n",
    "    scale_sparsity_penalty_by_decoder_norm=True,\n",
    "    decoder_heuristic_init=True,\n",
    "    init_encoder_as_decoder_transpose=True,\n",
    "    normalize_activations=\"expected_average_only_in\",\n",
    "    # Training Parameters\n",
    "    lr=5e-5,  # lower the better, we'll go fairly high to speed up the tutorial.\n",
    "    adam_beta1=0.9,  # adam params (default, but once upon a time we experimented with these.)\n",
    "    adam_beta2=0.999,\n",
    "    lr_scheduler_name=\"constant\",  # constant learning rate with warmup. Could be better schedules out there.\n",
    "    lr_warm_up_steps=lr_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lr_decay_steps=lr_decay_steps,  # this will help us avoid overfitting.\n",
    "    l1_coefficient=5,  # will control how sparse the feature activations are\n",
    "    l1_warm_up_steps=l1_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lp_norm=1.0,  # the L1 penalty (and not a Lp for p < 1)\n",
    "    train_batch_size_tokens=batch_size,\n",
    "    context_size=512,  # will control the lenght of the prompts we feed to the model. Larger is better but slower. so for the tutorial we'll use a short one.\n",
    "    # Activation Store Parameters\n",
    "    n_batches_in_buffer=64,  # controls how many activations we store / shuffle.\n",
    "    training_tokens=total_training_tokens,  # 100 million tokens is quite a few, but we want to see good stats. Get a coffee, come back.\n",
    "    store_batch_size_prompts=16,\n",
    "    # Resampling protocol\n",
    "    use_ghost_grads=False,  # we don't use ghost grads anymore.\n",
    "    feature_sampling_window=1000,  # this controls our reporting of feature sparsity stats\n",
    "    dead_feature_window=1000,  # would effect resampling or ghost grads if we were using it.\n",
    "    dead_feature_threshold=1e-4,  # would effect resampling or ghost grads if we were using it.\n",
    "    # WANDB\n",
    "    log_to_wandb=True,  # always use wandb unless you are just testing code.\n",
    "    wandb_project=\"sae_lens_tutorial\",\n",
    "    wandb_log_frequency=30,\n",
    "    eval_every_n_wandb_logs=20,\n",
    "    # Misc\n",
    "    device=device,\n",
    "    seed=42,\n",
    "    n_checkpoints=0,\n",
    "    checkpoint_path=\"checkpoints\",\n",
    "    dtype=\"float32\"\n",
    ")\n",
    "# look at the next cell to see some instruction for what to do while this is running.\n",
    "sparse_autoencoder = SAETrainingRunner(cfg).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do I save this ?\n",
    "sparse_autoencoder.save_model(path=\"sparse_autoencoder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16384, 1024])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "file_path = \"sparse_autoencoder.pt/sae_weights.safetensors\"\n",
    "\n",
    "# load the weights\n",
    "\n",
    "with safe_open(file_path, \"pt\") as f:\n",
    "    tensors = {k: f.get_tensor(k) for k in f.keys()}\n",
    "tensors['W_dec'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '8'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sae_data: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msparse_autoencoder.pt/sae_weights.safetensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "File \u001b[0;32m~/miniconda3/envs/othello-env/lib/python3.11/site-packages/torch/serialization.py:1040\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1039\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/othello-env/lib/python3.11/site-packages/torch/serialization.py:1262\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadinto\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1258\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load does not work with file-like objects that do not implement readinto on Python 3.8.0 and 3.8.1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1259\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived object of type \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(f)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m. Please update to Python 3.8.2 or newer to restore this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1260\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctionality.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1262\u001b[0m magic_number \u001b[38;5;241m=\u001b[39m \u001b[43mpickle_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic_number \u001b[38;5;241m!=\u001b[39m MAGIC_NUMBER:\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid magic number; corrupt file?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '8'."
     ]
    }
   ],
   "source": [
    "sae_data: dict = t.load(\"sparse_autoencoder.pt/sae_weights.safetensors\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxtyping import Float\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "import einops\n",
    "from dataclasses import dataclass\n",
    "from torch.nn import functional as F\n",
    "from safetensors import safe_open\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AutoEncoderConfig:\n",
    "    n_instances: int\n",
    "    n_input_ae: int\n",
    "    n_hidden_ae: int\n",
    "    l1_coeff: float = 0.5\n",
    "    tied_weights: bool = False\n",
    "    weight_normalize_eps: float = 1e-8\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    W_enc: Float[Tensor, \"n_instances n_input_ae n_hidden_ae\"]\n",
    "    W_dec: Float[Tensor, \"n_instances n_hidden_ae n_input_ae\"]\n",
    "    b_enc: Float[Tensor, \"n_instances n_hidden_ae\"]\n",
    "    b_dec: Float[Tensor, \"n_instances n_input_ae\"]\n",
    "\n",
    "\n",
    "    def __init__(self, cfg: AutoEncoderConfig):\n",
    "        '''\n",
    "        Initializes the two weights and biases according to the type signature above.\n",
    "\n",
    "        If self.cfg.tied_weights = True, then we only create W_enc, not W_dec.\n",
    "        '''\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.W_enc = nn.Parameter(nn.init.xavier_normal_(t.empty((cfg.n_instances, cfg.n_input_ae, cfg.n_hidden_ae))))\n",
    "        if not(cfg.tied_weights):\n",
    "            self.W_dec = nn.Parameter(nn.init.xavier_normal_(t.empty((cfg.n_instances, cfg.n_hidden_ae, cfg.n_input_ae))))\n",
    "\n",
    "        self.b_enc = nn.Parameter(t.zeros(cfg.n_instances, cfg.n_hidden_ae))\n",
    "        self.b_dec = nn.Parameter(t.zeros(cfg.n_instances, cfg.n_input_ae))\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "\n",
    "    def normalize_and_return_W_dec(self) -> Float[Tensor, \"n_instances n_hidden_ae n_input_ae\"]:\n",
    "        '''\n",
    "        If self.cfg.tied_weights = True, we return the normalized & transposed encoder weights.\n",
    "        If self.cfg.tied_weights = False, we normalize the decoder weights in-place, and return them.\n",
    "\n",
    "        Normalization should be over the `n_input_ae` dimension, i.e. each feature should have a noramlized decoder weight.\n",
    "        '''\n",
    "        if self.cfg.tied_weights:\n",
    "            return self.W_enc.transpose(-1, -2) / (self.W_enc.transpose(-1, -2).norm(dim=1, keepdim=True) + self.cfg.weight_normalize_eps)\n",
    "        else:\n",
    "            self.W_dec.data = self.W_dec.data / (self.W_dec.data.norm(dim=2, keepdim=True) + self.cfg.weight_normalize_eps)\n",
    "            return self.W_dec\n",
    "\n",
    "\n",
    "    def forward(self, h: Float[Tensor, \"batch_size n_instances n_input_ae\"]):\n",
    "        '''\n",
    "        Runs a forward pass on the autoencoder, and returns several outputs.\n",
    "\n",
    "        Inputs:\n",
    "            h: Float[Tensor, \"batch_size n_instances n_input_ae\"]\n",
    "                hidden activations generated from a Model instance\n",
    "\n",
    "        Returns:\n",
    "            l1_loss: Float[Tensor, \"batch_size n_instances\"]\n",
    "                L1 loss for each batch elem & each instance (sum over the `n_hidden_ae` dimension)\n",
    "            l2_loss: Float[Tensor, \"batch_size n_instances\"]\n",
    "                L2 loss for each batch elem & each instance (take mean over the `n_input_ae` dimension)\n",
    "            loss: Float[Tensor, \"\"]\n",
    "                Sum of L1 and L2 loss (with the former scaled by `self.cfg.l1_coeff). We sum over the `n_instances`\n",
    "                dimension but take mean over the batch dimension\n",
    "            acts: Float[Tensor, \"batch_size n_instances n_hidden_ae\"]\n",
    "                Activations of the autoencoder's hidden states (post-ReLU)\n",
    "            h_reconstructed: Float[Tensor, \"batch_size n_instances n_input_ae\"]\n",
    "                Reconstructed hidden states, i.e. the autoencoder's final output\n",
    "        '''\n",
    "        # Compute activations\n",
    "        h_cent = h - self.b_dec\n",
    "        acts = einops.einsum(\n",
    "            h_cent, self.W_enc,\n",
    "            \"batch_size n_instances n_input_ae, n_instances n_input_ae n_hidden_ae -> batch_size n_instances n_hidden_ae\"\n",
    "        )\n",
    "        acts = F.relu(acts + self.b_enc)\n",
    "\n",
    "        # Compute reconstructed input\n",
    "        h_reconstructed = einops.einsum(\n",
    "            acts, self.normalize_and_return_W_dec(),\n",
    "            \"batch_size n_instances n_hidden_ae, n_instances n_hidden_ae n_input_ae -> batch_size n_instances n_input_ae\"\n",
    "        ) + self.b_dec\n",
    "\n",
    "        # Compute loss, return values\n",
    "        l2_loss = (h_reconstructed - h).pow(2).mean(-1) # shape [batch_size n_instances]\n",
    "        l1_loss = acts.abs().sum(-1) # shape [batch_size n_instances]\n",
    "        loss = (self.cfg.l1_coeff * l1_loss + l2_loss).mean(0).sum() # scalar\n",
    "\n",
    "        return l1_loss, l2_loss, loss, acts, h_reconstructed\n",
    "    \n",
    "\n",
    "def load_autoencoder_from_path(path : str) -> AutoEncoder:\n",
    "    config_path = path + \"/cfg.json\"\n",
    "    weights_path = path + \"/sae_weights.safetensors\"\n",
    "    with safe_open(file_path, \"pt\") as f:\n",
    "        state_dict = {k: f.get_tensor(k) for k in f.keys()}\n",
    "\n",
    "    with open(config_path) as f:\n",
    "        sae_lens_config = json.load(f)\n",
    "\n",
    "    state_dict = {k : v.unsqueeze(0) for k, v in state_dict.items()}\n",
    "\n",
    "    cfg = AutoEncoderConfig(\n",
    "        n_instances = 1,\n",
    "        n_input_ae = sae_lens_config[\"d_in\"],\n",
    "        n_hidden_ae = sae_lens_config[\"d_sae\"],\n",
    "    )\n",
    "\n",
    "    # Initialize our model, and load in state dict\n",
    "    autoencoder = AutoEncoder(cfg)\n",
    "    autoencoder.load_state_dict(state_dict)\n",
    "\n",
    "    return autoencoder\n",
    "\n",
    "autoencoder = load_autoencoder_from_path(\"sparse_autoencoder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.W_enc.shape\n",
    "\n",
    "random_resid = t.randn((5, 1, 1024)).to(device)\n",
    "\n",
    "l1_loss, l2_loss, loss, acts, h_reconstructed = autoencoder(random_resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 16384])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"sparse_autoencoder.pt/sae_weights.safetensors\"\n",
    "\n",
    "# load the weights\n",
    "\n",
    "with safe_open(file_path, \"pt\") as f:\n",
    "    tensors = {k: f.get_tensor(k) for k in f.keys()}\n",
    "tensors['W_dec'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Assuming your tensor is named 'token_ids_tensor'\n",
    "# token_ids_tensor = torch.randint(0, 10000, (350000, 60))  # Example tensor\n",
    "\n",
    "# Convert tensor to list of dictionaries\n",
    "data = [{\"input_ids\": row.tolist()} for row in token_ids_tensor]\n",
    "\n",
    "# Create a Hugging Face Dataset\n",
    "dataset = Dataset.from_list(data)\n",
    "\n",
    "# Save the dataset locally (optional)\n",
    "dataset.save_to_disk(\"my_dataset\")\n",
    "\n",
    "# Upload to Hugging Face Hub\n",
    "api = HfApi()\n",
    "api.create_repo(repo_id=\"your-username/your-dataset-name\", exist_ok=True)\n",
    "dataset.push_to_hub(\"your-username/your-dataset-name\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "othello-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
