{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpi/fs00/home/jim.maar/miniconda3/envs/othello-env/lib/python3.11/site-packages/accelerate/utils/imports.py:274: UserWarning: `ACCELERATE_DISABLE_RICH` is deprecated and will be removed in v0.22.0 and deactivated by default. Please use `ACCELERATE_ENABLE_RICH` if you wish to use `rich`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpretability\n",
      "interpretability\n",
      "focus states: (50, 60, 8, 8)\n",
      "focus_valid_moves (50, 60, 64)\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "chapter = \"chapter1_transformer_interp\"\n",
    "repo = \"ARENA_3.0\"\n",
    "chapter_dir = r\"./\" if chapter in os.listdir() else os.getcwd().split(chapter)[0]\n",
    "sys.path.append(chapter_dir + f\"{chapter}/exercises\")\n",
    "\n",
    "import os\n",
    "os.environ[\"ACCELERATE_DISABLE_RICH\"] = \"1\"\n",
    "import sys\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import einops\n",
    "from ipywidgets import interact\n",
    "import plotly.express as px\n",
    "from ipywidgets import interact\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import random\n",
    "from IPython.display import display\n",
    "from jaxtyping import Float, Int, Bool, Shaped, jaxtyped\n",
    "from typing import List, Union, Optional, Tuple, Callable, Dict\n",
    "import typeguard\n",
    "from functools import partial\n",
    "# from torcheval.metrics.functional import multiclass_f1_score\n",
    "from sklearn.metrics import f1_score as multiclass_f1_score\n",
    "import copy\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import dataclasses\n",
    "import datasets\n",
    "from IPython.display import HTML\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import HookedRootModule, HookPoint\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "from tqdm.notebook import tqdm\n",
    "from dataclasses import dataclass\n",
    "from rich import print as rprint\n",
    "import pandas as pd\n",
    "\n",
    "# Make sure exercises are in the path\n",
    "# exercises_dir = Path(f\"{os.getcwd().split(chapter)[0]}/{chapter}/exercises\").resolve()\n",
    "# section_dir = exercises_dir / \"part6_othellogpt\"\n",
    "# section_dir = \"interpretability\"\n",
    "# if str(exercises_dir) not in sys.path: sys.path.append(str(exercises_dir))\n",
    "\n",
    "from plotly_utils import imshow\n",
    "from neel_plotly import scatter, line\n",
    "from generate_patches import generate_patch\n",
    "from pprint import pprint\n",
    "from utils import plot_game\n",
    "from training_utils import get_state_stack_num_flipped\n",
    "from utils import plot_probe_outputs\n",
    "from utils import seq_to_state_stack\n",
    "# import part6_othellogpt.tests as tests\n",
    "\n",
    "t.manual_seed(42)\n",
    "\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MAIN = __name__ == \"__main__\"\n",
    "\n",
    "cfg = HookedTransformerConfig(\n",
    "    n_layers = 8,\n",
    "    d_model = 512,\n",
    "    d_head = 64,\n",
    "    n_heads = 8,\n",
    "    d_mlp = 2048,\n",
    "    d_vocab = 61,\n",
    "    n_ctx = 59,\n",
    "    act_fn=\"gelu\",\n",
    "    normalization_type=\"LNPre\",\n",
    "    device=device,\n",
    ")\n",
    "model = HookedTransformer(cfg)\n",
    "\n",
    "sd = utils.download_file_from_hf(\"NeelNanda/Othello-GPT-Transformer-Lens\", \"synthetic_model.pth\")\n",
    "# champion_ship_sd = utils.download_file_from_hf(\"NeelNanda/Othello-GPT-Transformer-Lens\", \"championship_model.pth\")\n",
    "model.load_state_dict(sd)\n",
    "\n",
    "# An example input\n",
    "sample_input = t.tensor([[\n",
    "    20, 19, 18, 10,  2,  1, 27,  3, 41, 42, 34, 12,  4, 40, 11, 29, 43, 13, 48, 56,\n",
    "    33, 39, 22, 44, 24,  5, 46,  6, 32, 36, 51, 58, 52, 60, 21, 53, 26, 31, 37,  9,\n",
    "    25, 38, 23, 50, 45, 17, 47, 28, 35, 30, 54, 16, 59, 49, 57, 14, 15, 55, 7\n",
    "]]).to(device)\n",
    "\n",
    "# The argmax of the output (ie the most likely next move from each position)\n",
    "sample_output = t.tensor([[\n",
    "    21, 41, 40, 34, 40, 41,  3, 11, 21, 43, 40, 21, 28, 50, 33, 50, 33,  5, 33,  5,\n",
    "    52, 46, 14, 46, 14, 47, 38, 57, 36, 50, 38, 15, 28, 26, 28, 59, 50, 28, 14, 28,\n",
    "    28, 28, 28, 45, 28, 35, 15, 14, 30, 59, 49, 59, 15, 15, 14, 15,  8,  7,  8\n",
    "]]).to(device)\n",
    "\n",
    "assert (model(sample_input).argmax(dim=-1) == sample_output.to(device)).all()\n",
    "\n",
    "# os.chdir(section_dir)\n",
    "section_dir = Path.cwd()\n",
    "sys.path.append(str(section_dir))\n",
    "print(section_dir.name)\n",
    "\n",
    "OTHELLO_ROOT = (section_dir / \"othello_world\").resolve()\n",
    "OTHELLO_MECHINT_ROOT = (OTHELLO_ROOT / \"mechanistic_interpretability\").resolve()\n",
    "\n",
    "# if not OTHELLO_ROOT.exists():\n",
    "#     !git clone https://github.com/likenneth/othello_world\n",
    "\n",
    "sys.path.append(str(OTHELLO_MECHINT_ROOT))\n",
    "\n",
    "from mech_interp_othello_utils import (\n",
    "    plot_board,\n",
    "    plot_single_board,\n",
    "    plot_board_log_probs,\n",
    "    to_string,\n",
    "    to_int,\n",
    "    int_to_label,\n",
    "    string_to_label,\n",
    "    OthelloBoardState\n",
    ")\n",
    "\n",
    "# Load board data as ints (i.e. 0 to 60)\n",
    "board_seqs_int = t.tensor(np.load(OTHELLO_MECHINT_ROOT / \"board_seqs_int_small.npy\"), dtype=t.long)\n",
    "# Load board data as \"strings\" (i.e. 0 to 63 with middle squares skipped out)\n",
    "board_seqs_string = t.tensor(np.load(OTHELLO_MECHINT_ROOT / \"board_seqs_string_small.npy\"), dtype=t.long)\n",
    "\n",
    "assert all([middle_sq not in board_seqs_string for middle_sq in [27, 28, 35, 36]])\n",
    "assert board_seqs_int.max() == 60\n",
    "\n",
    "num_games, length_of_game = board_seqs_int.shape\n",
    "\n",
    "# Define possible indices (excluding the four center squares)\n",
    "stoi_indices = [i for i in range(64) if i not in [27, 28, 35, 36]]\n",
    "\n",
    "# Define our rows, and the function that converts an index into a (row, column) label, e.g. `E2`\n",
    "alpha = \"ABCDEFGH\"\n",
    "\n",
    "def to_board_label(i):\n",
    "    return f\"{alpha[i//8]}{i%8}\"\n",
    "\n",
    "# Get our list of board labels\n",
    "board_labels = list(map(to_board_label, stoi_indices))\n",
    "full_board_labels = list(map(to_board_label, range(64)))\n",
    "\n",
    "def plot_square_as_board(state, diverging_scale=True, **kwargs):\n",
    "    \"\"\"Takes a square input (8 by 8) and plot it as a board. Can do a stack of boards via facet_col=0\"\"\"\n",
    "    kwargs = {\n",
    "        \"y\": [i for i in alpha],\n",
    "        \"x\": [str(i) for i in range(8)],\n",
    "        \"color_continuous_scale\": \"RdBu\" if diverging_scale else \"Blues\",\n",
    "        \"color_continuous_midpoint\": 0. if diverging_scale else None,\n",
    "        \"aspect\": \"equal\",\n",
    "        **kwargs\n",
    "    }\n",
    "    imshow(state, **kwargs)\n",
    "\n",
    "start = 30000\n",
    "num_games = 50\n",
    "focus_games_int = board_seqs_int[start : start + num_games]\n",
    "focus_games_string = board_seqs_string[start: start + num_games]\n",
    "\n",
    "focus_logits, focus_cache = model.run_with_cache(focus_games_int[:, :-1].to(device))\n",
    "focus_logits.shape\n",
    "\n",
    "def one_hot(list_of_ints, num_classes=64):\n",
    "    out = t.zeros((num_classes,), dtype=t.float32)\n",
    "    out[list_of_ints] = 1.\n",
    "    return out\n",
    "\n",
    "focus_states = np.zeros((num_games, 60, 8, 8), dtype=np.float32)\n",
    "focus_valid_moves = t.zeros((num_games, 60, 64), dtype=t.float32)\n",
    "\n",
    "for i in (range(num_games)):\n",
    "    board = OthelloBoardState()\n",
    "    for j in range(60):\n",
    "        board.umpire(focus_games_string[i, j].item())\n",
    "        focus_states[i, j] = board.state\n",
    "        focus_valid_moves[i, j] = one_hot(board.get_valid_moves())\n",
    "\n",
    "print(\"focus states:\", focus_states.shape)\n",
    "print(\"focus_valid_moves\", tuple(focus_valid_moves.shape))\n",
    "\n",
    "# full_linear_probe = t.load(OTHELLO_MECHINT_ROOT / \"main_linear_probe.pth\", map_location=device)\n",
    "\n",
    "linear_probe2 = t.load(\"probes/linear/resid_6_linear.pth\")\n",
    "\n",
    "rows = 8\n",
    "cols = 8\n",
    "options = 3\n",
    "assert linear_probe2.shape == (1, cfg.d_model, rows, cols, options)\n",
    "\n",
    "black_to_play_index = 0\n",
    "white_to_play_index = 1\n",
    "blank_index = 0\n",
    "their_index = 1\n",
    "my_index = 2\n",
    "\n",
    "# Creating values for linear probe (converting the \"black/white to play\" notation into \"me/them to play\")\n",
    "\n",
    "'''LAYER = 6\n",
    "game_index = 0\n",
    "move = 29'''\n",
    "\n",
    "BLANK1 = 0\n",
    "BLACK = 1\n",
    "WHITE = -1\n",
    "\n",
    "# MINE = 0\n",
    "# YOURS = 1\n",
    "# BLANK2 = 2\n",
    "\n",
    "EMPTY = 0\n",
    "YOURS = 1\n",
    "MINE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import visualize_game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n",
    "- Plan:\n",
    "    - We want something that takes a handcoded Algorithm and evaluates how good it is\n",
    "    - Input depends on Layer\n",
    "        - Layer 0: All the Previous Moves.\n",
    "        - Layer n > 1: All the Previous Moves + All the Board Logits of the last Layers of the previous and the current moves\n",
    "        - Also the Flipped Probs\n",
    "        - Should I just use the Cache ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Probes\n",
    "linear_probes = []\n",
    "flipped_probes = []\n",
    "for layer in range(8):\n",
    "    linear_probe = t.load(f\"probes/linear/resid_{layer}_linear.pth\").to(device)\n",
    "    flipped_probe = t.load(f\"probes/flipped/resid_{layer}_flipped.pth\").to(device)\n",
    "    linear_probes.append(linear_probe)\n",
    "    flipped_probes.append(flipped_probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_logits(resid : Float[Tensor, \"batch pos d_model\"], layer : Int):\n",
    "    linear_probes = linear_probes[layer]\n",
    "    flipped_probe = flipped_probes[layer]\n",
    "    board_logits = einops.einsum(resid, linear_probe, 'batch seq d_model, modes d_model rows cols options -> model batch seq rows cols options')[0]\n",
    "    flipped_logits = einops.einsum(resid, flipped_probe, 'batch seq d_model, modes d_model rows cols options -> model batch seq rows cols options')[0]\n",
    "    return board_logits, flipped_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Algo():\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "    \n",
    "    def forward(self, resid : Float[Tensor, \"batch pos d_model\"], layer) -> Tuple[Float[Tensor, \"batch pos rows cols options\"], Float[Tensor, \"batch pos rows cols options\"]]:\n",
    "        pass\n",
    "\n",
    "    def get_random_variation(self, change_factor : float):\n",
    "        params_new = dict()\n",
    "        for key, value in self.params.items():\n",
    "            params_new[key] = value + t.randn_like(value) * value * change_factor\n",
    "        return Algo(params_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class history_circuit(Algo):\n",
    "    def __init__(self, params):\n",
    "        # Hyperparams: How far to go back, Threshhold where you count a tile as Flipped, Threshhold for Mine/Yours\n",
    "        super().__init__(params)\n",
    "        self.mine_threshold = self.paramas[\"mine_threshold\"]\n",
    "        self.flipped_threshold = self.paramas[\"flipped_threshold\"]\n",
    "\n",
    "    def forward(self, prev_resid : Float[Tensor, \"batch pos d_model\"], prev_layer) -> Tuple[Float[Tensor, \"batch pos rows cols options\"], Float[Tensor, \"batch pos rows cols options\"]]:\n",
    "\n",
    "        # Go over each previous position B of layer -1\n",
    "        # Check what Color the Tile should be...\n",
    "        #    From the Beginning the first time the MINE/YOURS is above a certain Threshhold count the tile as Mine / Yours, then count the Flipped ... (Not what the model is acutally doing though)\n",
    "        #    I could try other Things like: Look at the Last time the Tile has been Flipped, this is probably the Color\n",
    "        #        If the Tile has not been Flipped => First Placed ...\n",
    "        #        I could first visulize and look what makes sense. Or I just code it out and try different things (better evidence I think, but I need to have good code for fast feedback loops)\n",
    "        # If Tile has Flipped at Pos A in the Last Layer, then it should be the opposite color\n",
    "        # If Tile has not Flipped, then it should be the same color\n",
    "        batch, seq_len, _ = prev_resid.shape\n",
    "        board_logits_prev, flipped_logits_prev = get_feature_logits(prev_resid, prev_layer)\n",
    "        board_logits_new = t.zeros((batch, seq_len, 8, 8, 3))\n",
    "        for pos in range(seq_len):\n",
    "            logits_at_pos = board_logits_prev[:, pos]\n",
    "            flipped_at_pos = flipped_logits_prev[:, pos]\n",
    "        \n",
    "\n",
    "def flipping_circuit():\n",
    "    # Goes in all directionns and if YOURS, turn into MINE with Flipped, until you hit a MINE without Flipped\n",
    "    # Threshold for when a Tile is counted as Flipped\n",
    "    # Threshold for when a Tile is counted as MINE vs YOURS\n",
    "    pass\n",
    "\n",
    "def layer_n_algo(layer):\n",
    "    # Do all positions at the same time or go over each position?\n",
    "    # Go over each Tile\n",
    "    # If Blank, leave Blank\n",
    "    # Else do History Circuit\n",
    "    # Using the update from the History Circuit do Flipping Circuit \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(layer: Int, model: HookedTransformer):\n",
    "    assert 0 <= layer < 8\n",
    "    # Use focus_cache ...\n",
    "    # Do I want to give 1 game or many to the function? I think many is better. I might want to scale this\n",
    "    # alog function should return the board_logits and the flipped logits\n",
    "    # get the real board_logits\n",
    "    # batch, seq, d_model\n",
    "    resid = focus_cache[\"resid_post\", layer]\n",
    "    # modes, d_model, rows, cols, options\n",
    "    board_logits, flipped_logits = get_feature_logits(resid, layer)\n",
    "    board_logits_pred, flipped_logits_pred = layer_n_algo(layer)\n",
    "    board_correct = board_logits.argmax(dim=-1)\n",
    "    flipped_correct = flipped_logits.argmax(dim=-1)\n",
    "    board_pred = board_logits_pred.argmax(dim=-1)\n",
    "    flipped_pred = flipped_logits_pred.argmax(dim=-1)\n",
    "    # Calculate the Accuracy\n",
    "    board_accuracy = (board_correct == board_pred).float().mean()\n",
    "    flipped_accuracy = (flipped_correct == flipped_pred).float().mean()\n",
    "    return board_accuracy, flipped_accuracy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "othello-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
