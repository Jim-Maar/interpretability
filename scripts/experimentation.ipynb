{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "chapter = \"chapter1_transformer_interp\"\n",
    "repo = \"ARENA_3.0\"\n",
    "chapter_dir = r\"./\" if chapter in os.listdir() else os.getcwd().split(chapter)[0]\n",
    "sys.path.append(chapter_dir + f\"{chapter}/exercises\")\n",
    "\n",
    "import os\n",
    "os.environ[\"ACCELERATE_DISABLE_RICH\"] = \"1\"\n",
    "import sys\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import einops\n",
    "from ipywidgets import interact\n",
    "import plotly.express as px\n",
    "from ipywidgets import interact\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import random\n",
    "from IPython.display import display\n",
    "from jaxtyping import Float, Int, Bool, Shaped, jaxtyped\n",
    "from typing import List, Union, Optional, Tuple, Callable, Dict\n",
    "import typeguard\n",
    "from functools import partial\n",
    "# from torcheval.metrics.functional import multiclass_f1_score\n",
    "from sklearn.metrics import f1_score as multiclass_f1_score\n",
    "import copy\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import dataclasses\n",
    "import datasets\n",
    "from IPython.display import HTML\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import HookedRootModule, HookPoint\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "from tqdm.notebook import tqdm\n",
    "from dataclasses import dataclass\n",
    "from rich import print as rprint\n",
    "import pandas as pd\n",
    "\n",
    "# Make sure exercises are in the path\n",
    "# exercises_dir = Path(f\"{os.getcwd().split(chapter)[0]}/{chapter}/exercises\").resolve()\n",
    "# section_dir = exercises_dir / \"part6_othellogpt\"\n",
    "# section_dir = \"interpretability\"\n",
    "# if str(exercises_dir) not in sys.path: sys.path.append(str(exercises_dir))\n",
    "\n",
    "from plotly_utils import imshow\n",
    "from neel_plotly import scatter, line\n",
    "import part6_othellogpt.tests as tests\n",
    "\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "\n",
    "t.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN = __name__ == \"__main__\"\n",
    "\n",
    "cfg = HookedTransformerConfig(\n",
    "    n_layers = 8,\n",
    "    d_model = 512,\n",
    "    d_head = 64,\n",
    "    n_heads = 8,\n",
    "    d_mlp = 2048,\n",
    "    d_vocab = 61,\n",
    "    n_ctx = 59,\n",
    "    act_fn=\"gelu\",\n",
    "    normalization_type=\"LNPre\",\n",
    "    device=device,\n",
    ")\n",
    "model = HookedTransformer(cfg)\n",
    "\n",
    "sd = utils.download_file_from_hf(\"NeelNanda/Othello-GPT-Transformer-Lens\", \"synthetic_model.pth\")\n",
    "# champion_ship_sd = utils.download_file_from_hf(\"NeelNanda/Othello-GPT-Transformer-Lens\", \"championship_model.pth\")\n",
    "model.load_state_dict(sd)\n",
    "\n",
    "# An example input\n",
    "sample_input = t.tensor([[\n",
    "    20, 19, 18, 10,  2,  1, 27,  3, 41, 42, 34, 12,  4, 40, 11, 29, 43, 13, 48, 56,\n",
    "    33, 39, 22, 44, 24,  5, 46,  6, 32, 36, 51, 58, 52, 60, 21, 53, 26, 31, 37,  9,\n",
    "    25, 38, 23, 50, 45, 17, 47, 28, 35, 30, 54, 16, 59, 49, 57, 14, 15, 55, 7\n",
    "]]).to(device)\n",
    "\n",
    "# The argmax of the output (ie the most likely next move from each position)\n",
    "sample_output = t.tensor([[\n",
    "    21, 41, 40, 34, 40, 41,  3, 11, 21, 43, 40, 21, 28, 50, 33, 50, 33,  5, 33,  5,\n",
    "    52, 46, 14, 46, 14, 47, 38, 57, 36, 50, 38, 15, 28, 26, 28, 59, 50, 28, 14, 28,\n",
    "    28, 28, 28, 45, 28, 35, 15, 14, 30, 59, 49, 59, 15, 15, 14, 15,  8,  7,  8\n",
    "]]).to(device)\n",
    "\n",
    "assert (model(sample_input).argmax(dim=-1) == sample_output.to(device)).all()\n",
    "\n",
    "# os.chdir(section_dir)\n",
    "section_dir = Path.cwd()\n",
    "assert section_dir.name == \"interpretability\"\n",
    "\n",
    "OTHELLO_ROOT = (section_dir / \"othello_world\").resolve()\n",
    "OTHELLO_MECHINT_ROOT = (OTHELLO_ROOT / \"mechanistic_interpretability\").resolve()\n",
    "\n",
    "# if not OTHELLO_ROOT.exists():\n",
    "#     !git clone https://github.com/likenneth/othello_world\n",
    "\n",
    "sys.path.append(str(OTHELLO_MECHINT_ROOT))\n",
    "\n",
    "from mech_interp_othello_utils import (\n",
    "    plot_board,\n",
    "    plot_single_board,\n",
    "    plot_board_log_probs,\n",
    "    to_string,\n",
    "    to_int,\n",
    "    int_to_label,\n",
    "    string_to_label,\n",
    "    OthelloBoardState\n",
    ")\n",
    "\n",
    "# Load board data as ints (i.e. 0 to 60)\n",
    "board_seqs_int = t.tensor(np.load(OTHELLO_MECHINT_ROOT / \"board_seqs_int_small.npy\"), dtype=t.long)\n",
    "# Load board data as \"strings\" (i.e. 0 to 63 with middle squares skipped out)\n",
    "board_seqs_string = t.tensor(np.load(OTHELLO_MECHINT_ROOT / \"board_seqs_string_small.npy\"), dtype=t.long)\n",
    "\n",
    "assert all([middle_sq not in board_seqs_string for middle_sq in [27, 28, 35, 36]])\n",
    "assert board_seqs_int.max() == 60\n",
    "\n",
    "num_games, length_of_game = board_seqs_int.shape\n",
    "\n",
    "# Define possible indices (excluding the four center squares)\n",
    "stoi_indices = [i for i in range(64) if i not in [27, 28, 35, 36]]\n",
    "\n",
    "# Define our rows, and the function that converts an index into a (row, column) label, e.g. `E2`\n",
    "alpha = \"ABCDEFGH\"\n",
    "\n",
    "def to_board_label(i):\n",
    "    return f\"{alpha[i//8]}{i%8}\"\n",
    "\n",
    "# Get our list of board labels\n",
    "board_labels = list(map(to_board_label, stoi_indices))\n",
    "full_board_labels = list(map(to_board_label, range(64)))\n",
    "\n",
    "def plot_square_as_board(state, diverging_scale=True, **kwargs):\n",
    "    \"\"\"Takes a square input (8 by 8) and plot it as a board. Can do a stack of boards via facet_col=0\"\"\"\n",
    "    kwargs = {\n",
    "        \"y\": [i for i in alpha],\n",
    "        \"x\": [str(i) for i in range(8)],\n",
    "        \"color_continuous_scale\": \"RdBu\" if diverging_scale else \"Blues\",\n",
    "        \"color_continuous_midpoint\": 0. if diverging_scale else None,\n",
    "        \"aspect\": \"equal\",\n",
    "        **kwargs\n",
    "    }\n",
    "    imshow(state, **kwargs)\n",
    "\n",
    "num_games = 50\n",
    "focus_games_int = board_seqs_int[:num_games]\n",
    "focus_games_string = board_seqs_string[:num_games]\n",
    "\n",
    "focus_logits, focus_cache = model.run_with_cache(focus_games_int[:, :-1].to(device))\n",
    "focus_logits.shape\n",
    "\n",
    "full_linear_probe = t.load(OTHELLO_MECHINT_ROOT / \"main_linear_probe.pth\", map_location=device)\n",
    "\n",
    "rows = 8\n",
    "cols = 8\n",
    "options = 3\n",
    "assert full_linear_probe.shape == (3, cfg.d_model, rows, cols, options)\n",
    "\n",
    "black_to_play_index = 0\n",
    "white_to_play_index = 1\n",
    "blank_index = 0\n",
    "their_index = 1\n",
    "my_index = 2\n",
    "\n",
    "# Creating values for linear probe (converting the \"black/white to play\" notation into \"me/them to play\")\n",
    "linear_probe = t.zeros(cfg.d_model, rows, cols, options, device=device)\n",
    "linear_probe[..., blank_index] = 0.5 * (full_linear_probe[black_to_play_index, ..., 0] + full_linear_probe[white_to_play_index, ..., 0])\n",
    "linear_probe[..., their_index] = 0.5 * (full_linear_probe[black_to_play_index, ..., 1] + full_linear_probe[white_to_play_index, ..., 2])\n",
    "linear_probe[..., my_index] = 0.5 * (full_linear_probe[black_to_play_index, ..., 2] + full_linear_probe[white_to_play_index, ..., 1])\n",
    "\n",
    "layer = 6\n",
    "game_index = 0\n",
    "move = 29\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_probe_outputs_intervention(layer, game_index, move, **kwargs):\n",
    "    residual_stream = focus_cache[\"resid_post\", layer][game_index, move]\n",
    "    probe = t.load(\n",
    "        os.path.join(\n",
    "            f\"models/flipped_L{layer}.pth\",\n",
    "        )\n",
    "    )\n",
    "    # print(\"residual_stream\", residual_stream.shape)\n",
    "    probe_out = einops.einsum(residual_stream, linear_probe, \"d_model, d_model row col options -> row col options\")\n",
    "    probabilities = probe_out.softmax(dim=-1)\n",
    "    plot_square_as_board(probabilities, facet_col=2, facet_labels=[\"P(Empty)\", \"P(Their's)\", \"P(Mine)\"], **kwargs)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
